{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAuMVCwfWs8"
      },
      "source": [
        "# Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir9zwETrfbrp"
      },
      "source": [
        "# ‚úÖ 1) Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZT1f24vHffuf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TTCS8rpJX4q"
      },
      "source": [
        "# ‚úÖ 2) Cr√©ation du dossier output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tjQB5-MjJSyG"
      },
      "outputs": [],
      "source": [
        "os.makedirs('models', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ47JAxrgmaL"
      },
      "source": [
        "# ‚úÖ 3) Charger les datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1xiv3pJOgqY3"
      },
      "outputs": [],
      "source": [
        "dataset_train = pd.read_csv('Transformers_Training_Set.csv')\n",
        "dataset_test = pd.read_csv('Transformers_Test_Set.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT8_2UJegtG5"
      },
      "source": [
        "# ‚úÖ 4) Param√®tres globaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OTrF2kR7gx9x"
      },
      "outputs": [],
      "source": [
        "smell_names = dataset_train.columns[1:]  # sans 'Release version'\n",
        "num_smells = len(smell_names)\n",
        "timestep = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyYgYocqhNUg"
      },
      "source": [
        "# ‚úÖ 5) Boucle sur chaque smell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iofU21B0i6ST",
        "outputId": "df379d1c-ebdf-487b-9627-54f91bc30986"
      },
      "outputs": [],
      "source": [
        "print(smell_names)\n",
        "\n",
        "for target_index, smell_name in enumerate(smell_names):\n",
        "    print(f'=== Training for smell: {smell_name} ===')\n",
        "\n",
        "    # Extraire colonnes [Release, smell]\n",
        "    train_values = dataset_train.iloc[:, [target_index + 1]].values\n",
        "    test_values = dataset_test.iloc[:, [target_index + 1]].values\n",
        "\n",
        "    # Construire X_train, y_train une seule fois (avec scaling dans objective)\n",
        "    dataset_total = np.concatenate((train_values, test_values), axis=0)\n",
        "\n",
        "    # Scaler sp√©cifique\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    train_scaled = sc.fit_transform(train_values)\n",
        "    total_scaled = sc.transform(dataset_total)\n",
        "\n",
        "    # Construire X_train, y_train\n",
        "    X_train, y_train = [], []\n",
        "    for i in range(timestep, len(train_scaled)):\n",
        "        X_train.append(train_scaled[i - timestep:i])\n",
        "        y_train.append(train_scaled[i])\n",
        "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "    # Construire mod√®le\n",
        "    regressor = Sequential()\n",
        "    regressor.add(LSTM(units=64, return_sequences=True, input_shape=(timestep, 1)))\n",
        "    regressor.add(Dropout(0.2))\n",
        "    regressor.add(LSTM(units=64))\n",
        "    regressor.add(Dropout(0.2))\n",
        "    regressor.add(Dense(units=1))\n",
        "    regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Entra√Æner\n",
        "    regressor.fit(X_train, y_train, epochs=100, batch_size=8, verbose=0)\n",
        "\n",
        "    # Pr√©parer X_test\n",
        "    dataset_total = np.concatenate((train_values, test_values), axis=0)\n",
        "    inputs_scaled = sc.transform(dataset_total)\n",
        "    X_test = []\n",
        "    for i in range(len(train_values), len(inputs_scaled)):\n",
        "        X_test.append(inputs_scaled[i - timestep:i])\n",
        "    X_test = np.array(X_test)\n",
        "\n",
        "    # Pr√©dire\n",
        "    predicted_scaled = regressor.predict(X_test)\n",
        "    predicted = sc.inverse_transform(predicted_scaled)\n",
        "\n",
        "    # Courbe\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(test_values, color='red', label='Valeurs r√©elles')\n",
        "    plt.plot(predicted, color='blue', label='Pr√©dictions')\n",
        "    plt.title(f'Pr√©diction ‚Äì Smell : {smell_name}')\n",
        "    plt.xlabel('Release')\n",
        "    plt.ylabel('Nombre de smells')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'models/{smell_name}_prediction.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Sauvegarder mod√®le et scaler\n",
        "    regressor.save(f'models/{smell_name}_model.h5')\n",
        "    joblib.dump(sc, f'models/{smell_name}_scaler.save')\n",
        "\n",
        "    # Pr√©dire la prochaine release\n",
        "    last_inputs = inputs_scaled[-timestep:]\n",
        "    last_inputs = np.expand_dims(last_inputs, axis=0)\n",
        "    next_scaled = regressor.predict(last_inputs)\n",
        "    next_value = sc.inverse_transform(next_scaled)\n",
        "    print(f'üëâ Pr√©diction pour la prochaine release ({smell_name}) : {next_value[0][0]:.2f}')\n",
        "\n",
        "    # Evaluer sur test\n",
        "    X_test = []\n",
        "    for i in range(len(train_values), len(total_scaled)):\n",
        "        X_test.append(total_scaled[i - timestep:i])\n",
        "    X_test = np.array(X_test)\n",
        "    predicted_scaled = regressor.predict(X_test, verbose=0)\n",
        "    predicted = sc.inverse_transform(predicted_scaled)\n",
        "    rmse = np.sqrt(mean_squared_error(test_values, predicted))\n",
        "\n",
        "    print(\"RMSE :\", rmse)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n‚úÖ Tous les mod√®les sont entra√Æn√©s et sauvegard√©s dans le dossier 'models'.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
