# -*- coding: utf-8 -*-
"""transformers-count-of-smells-solution-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1moZsopzHh__VBgTr-uOopwB4GVe0f7Nq

# Recurrent Neural Network

# 1) Imports
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
import joblib
import os
from sklearn.metrics import mean_squared_error

"""# 2) Load the datasets


"""

dataset_train = pd.read_csv('Transformers_Training_Set.csv')
dataset_test = pd.read_csv('Transformers_Test_Set.csv')

"""# 3) Global parameters"""

smell_names = dataset_train.columns[1:]  # without 'Release version'
num_smells = len(smell_names)
timestep_list = [1, 3, 5, 10]

"""# 4) Loop on each smell"""

print(smell_names)

for target_index, smell_name in enumerate(smell_names):
    print(f'=== Training for smell: {smell_name} ===')

    # Extract columns [Release, smell]
    train_values = dataset_train.iloc[:, [target_index + 1]].values
    test_values = dataset_test.iloc[:, [target_index + 1]].values

    dataset_total = np.concatenate((train_values, test_values), axis=0)

    # Figure for all timestep curves
    plt.figure(figsize=(12, 6))

    # Always display the true values
    plt.plot(test_values, color='black', label='True values', linewidth=2)

    for timestep in timestep_list:
        print(f'Timestep: {timestep}')

        # Scaler
        sc = MinMaxScaler(feature_range=(0, 1))
        train_scaled = sc.fit_transform(train_values)
        total_scaled = sc.transform(dataset_total)

        # Build X_train, y_train
        X_train, y_train = [], []
        for i in range(timestep, len(train_scaled)):
            X_train.append(train_scaled[i - timestep:i])
            y_train.append(train_scaled[i])
        X_train, y_train = np.array(X_train), np.array(y_train)

        # Reshape if timestep == 1
        if timestep == 1:
            X_train = X_train.reshape((X_train.shape[0], timestep, 1))

        # Model
        regressor = Sequential()
        regressor.add(LSTM(units=64, return_sequences=True, input_shape=(timestep, 1)))
        regressor.add(Dropout(0.2))
        regressor.add(LSTM(units=64))
        regressor.add(Dropout(0.2))
        regressor.add(Dense(units=1))
        regressor.compile(optimizer='adam', loss='mean_squared_error')

        # Train
        regressor.fit(X_train, y_train, epochs=100, batch_size=8, verbose=0)

        # Prepare X_test
        inputs_scaled = sc.transform(dataset_total)
        X_test = []
        for i in range(len(train_values), len(inputs_scaled)):
            X_test.append(inputs_scaled[i - timestep:i])
        X_test = np.array(X_test)

        if timestep == 1:
            X_test = X_test.reshape((X_test.shape[0], timestep, 1))

        # Predict
        predicted_scaled = regressor.predict(X_test)
        predicted = sc.inverse_transform(predicted_scaled)

        # Add curve to the plot
        plt.plot(predicted, label=f'Prediction timestep={timestep}')

        # Save model and scaler for the last timestep only (optional)
        if timestep == timestep_list[-1]:
            regressor.save(f'models/{smell_name}_model_timestep{timestep}.h5')
            joblib.dump(sc, f'models/{smell_name}_scaler_timestep{timestep}.save')

        # Evaluate
        rmse = np.sqrt(mean_squared_error(test_values, predicted))
        print(f"RMSE (timestep={timestep}):", rmse)

    plt.title(f'Predictions for smell: {smell_name}')
    plt.xlabel('Release')
    plt.ylabel('Number of smells')
    plt.legend()
    plt.grid(True)
    plt.show()

print("\nAll multi-timestep models have been trained.")