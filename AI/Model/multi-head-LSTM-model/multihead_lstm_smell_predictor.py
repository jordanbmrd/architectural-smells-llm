# -*- coding: utf-8 -*-
"""multihead_lstm_smell_predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yPWAGDfbQABdgaXPtYKEwYYZhxXhYqtu
"""

# Partie 1 - Import des bibliothèques
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import re
from sklearn.preprocessing import MinMaxScaler
from keras.models import Model
from keras.layers import Input, LSTM, Dropout, Dense
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Partie 2 - Chargement des datasets
dataset_train = pd.read_csv('celery_Training_Set.csv')
dataset_test = pd.read_csv('celery_Test_Set.csv')

# Partie 3 - Nettoyage des noms de smells
def clean_smell_names(names):
    return [re.sub(r'[^A-Za-z0-9_]+', '_', name).strip('_') for name in names]

original_smell_names = list(dataset_train.columns[1:])
clean_names = clean_smell_names(original_smell_names)
num_smells = len(clean_names)
timestep = 2

# Partie 4 - Préparation des données
def prepare_data(df_train, df_test, col_index, timestep):
    train_vals = df_train.iloc[:, [col_index + 1]].values
    test_vals = df_test.iloc[:, [col_index + 1]].values
    full_vals = np.concatenate((train_vals, test_vals), axis=0)

    scaler = MinMaxScaler()
    train_scaled = scaler.fit_transform(train_vals)
    full_scaled = scaler.transform(full_vals)

    X_train, y_train = [], []
    for i in range(timestep, len(train_scaled)):
        X_train.append(train_scaled[i - timestep:i])
        y_train.append(train_scaled[i])
    X_train, y_train = np.array(X_train), np.array(y_train)

    X_test = []
    for i in range(len(train_vals), len(full_scaled)):
        X_test.append(full_scaled[i - timestep:i])
    X_test = np.array(X_test)

    return X_train, y_train, X_test, test_vals, scaler

data = {}
scalers = {}

for i, name in enumerate(clean_names):
    X_train, y_train, X_test, real_vals, scaler = prepare_data(dataset_train, dataset_test, i, timestep)
    data[name] = {'X_train': X_train, 'y_train': y_train, 'X_test': X_test, 'real': real_vals}
    scalers[name] = scaler

# Partie 5 - Création du modèle multi-head
def build_multihead_model(timestep, names):
    inputs, outputs = [], []
    for name in names:
        inp = Input(shape=(timestep, 1), name=f'input_{name}')
        x = LSTM(64, return_sequences=True)(inp)
        x = Dropout(0.2)(x)
        x = LSTM(64)(x)
        x = Dropout(0.2)(x)
        out = Dense(1, name=f'output_{name}')(x)
        inputs.append(inp)
        outputs.append(out)
    return Model(inputs=inputs, outputs=outputs)

model = build_multihead_model(timestep, clean_names)

losses = {f'output_{name}': 'mse' for name in clean_names}
metrics = {f'output_{name}': ['mae'] for name in clean_names}
model.compile(optimizer='adam', loss=losses, metrics=metrics)

model.summary()

# Partie 6 - Entraînement du modèle
X_train_dict = {f'input_{name}': data[name]['X_train'] for name in clean_names}
y_train_dict = {f'output_{name}': data[name]['y_train'] for name in clean_names}

callbacks = [
    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, verbose=1, min_lr=1e-6)
]

history = model.fit(X_train_dict, y_train_dict, epochs=100, batch_size=8, validation_split=0.2, callbacks=callbacks, verbose=1)

# Partie 7 - Prédictions et visualisation
rmse_scores = {}
mae_scores = {}

for name, original_name in zip(clean_names, original_smell_names):
    X_test = data[name]['X_test']
    true_values = data[name]['real']

    # Préparer les inputs pour toutes les têtes du modèle
    X_input_dict = {
        f'input_{other_name}': data[other_name]['X_test'] if other_name == name else np.zeros_like(data[other_name]['X_test'])
        for other_name in clean_names
    }

    # Prédire toutes les sorties
    preds_all = model.predict(X_input_dict, verbose=0)
    pred_scaled = preds_all[clean_names.index(name)]
    pred_denorm = scalers[name].inverse_transform(pred_scaled)

    # Calcul des métriques
    rmse = np.sqrt(mean_squared_error(true_values, pred_denorm))
    mae = mean_absolute_error(true_values, pred_denorm)
    rmse_scores[original_name] = rmse
    mae_scores[original_name] = mae

    # Affichage des scores
    print(f"{original_name}:")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  MAE: {mae:.4f}")

    # Affichage des courbes
    plt.figure()
    plt.plot(true_values, color='red', label='Valeurs réelles')
    plt.plot(pred_denorm, color='blue', label='Valeurs prédites')
    plt.title(f'Prédiction du smell : {original_name}')
    plt.xlabel('Temps')
    plt.ylabel('Nombre de smells')
    plt.legend()
    plt.show()